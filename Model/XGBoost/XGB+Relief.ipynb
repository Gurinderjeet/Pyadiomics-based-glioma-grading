{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GssaepCpQfOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install xgboost\n",
        "\n",
        "import io\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import statistics\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "hgg1=pd.read_csv(\"\")#Path to csv\n",
        "lgg1=pd.read_csv(\"\")\n",
        "\n",
        "lgg1[\"GRADE\"]=0\n",
        "hgg1[\"GRADE\"]=1\n",
        "hgg= hgg1.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "lgg= lgg1.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "!pip install ReliefF\n",
        "from ReliefF import ReliefF\n",
        "\n",
        "\n",
        "auc_lr=[]\n",
        "pre_lr=[]\n",
        "rec_lr=[]\n",
        "acc_lr=[]\n",
        "f1_lr=[]\n",
        "auc_lrt=[]\n",
        "pre_lrt=[]\n",
        "rec_lrt=[]\n",
        "acc_lrt=[]\n",
        "f1_lrt=[]\n",
        "\n",
        "master=pd.concat([lgg, hgg])\n",
        "master= master.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "Y=master[\"GRADE\"]\n",
        "master= master.drop(\"GRADE\", axis=1)\n",
        "master = (master - master.min()) / (master.max() - master.min())\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=False)\n",
        "for train_index, test_index in cv.split(master, Y):\n",
        "    #print(\"Train Index: \", train_index, \"\\n\")\n",
        "    #print(\"Test Index: \", test_index)\n",
        "\n",
        "    X_train, X_test = master.iloc[train_index], master.iloc[test_index]\n",
        "    Y_train, Y_test= Y.iloc[train_index], Y.iloc[test_index]\n",
        "\n",
        "    X_train= X_train.values\n",
        "    X_test= X_test.values\n",
        "    Y_train= Y_train.values\n",
        "    Y_test= Y_test.values\n",
        "\n",
        "    clf = make_pipeline(ReliefF(n_features_to_keep=55, n_neighbors=25),\n",
        "                    XGBClassifier(n_estimators=500, max_depth=1, learning_rate=0.08, min_child_weight=1))\n",
        "    \n",
        "    clf.fit(X_train, Y_train)\n",
        "\n",
        "    pred = clf.predict(X_test)\n",
        "    pre_l = precision_score(Y_test, pred)\n",
        "    rec_l = recall_score(Y_test, pred)\n",
        "    acc_l = accuracy_score(Y_test, pred)\n",
        "    probs = clf.predict_proba(X_test)\n",
        "    probs = probs[:, 1]\n",
        "    auc_l = roc_auc_score(Y_test, probs)\n",
        "    f1_l=f1_score(Y_test, pred)\n",
        "\n",
        "    pred = clf.predict(X_train)\n",
        "    pre_lt = precision_score(Y_train, pred)\n",
        "    rec_lt = recall_score(Y_train, pred)\n",
        "    acc_lt = accuracy_score(Y_train, pred)\n",
        "    probs = clf.predict_proba(X_train)\n",
        "    probs = probs[:, 1]\n",
        "    auc_lt = roc_auc_score(Y_train, probs)\n",
        "    f1_lt = f1_score(Y_train, pred)\n",
        "\n",
        "\n",
        "    auc_lr.append(auc_l)\n",
        "    pre_lr.append(pre_l)\n",
        "    rec_lr.append(rec_l)\n",
        "    acc_lr.append(acc_l)\n",
        "    f1_lr.append(f1_l)\n",
        "\n",
        "    auc_lrt.append(auc_lt)\n",
        "    pre_lrt.append(pre_lt)\n",
        "    rec_lrt.append(rec_lt)\n",
        "    acc_lrt.append(acc_lt)\n",
        "    f1_lrt.append(f1_lt)\n",
        "\n",
        "\n",
        "print(\"TRAIN:\")\n",
        "print(\"PRE:\", statistics.mean(pre_lrt))\n",
        "print(\"REC:\", statistics.mean(rec_lrt))\n",
        "print(\"ACC:\", statistics.mean(acc_lrt))\n",
        "print(\"AUC:\", statistics.mean(auc_lrt))\n",
        "print(\"F1:\", statistics.mean(f1_lrt))\n",
        "\n",
        "print(\"TEST:\")\n",
        "print(\"PRE:\", statistics.mean(pre_lr))\n",
        "print(\"REC:\", statistics.mean(rec_lr))\n",
        "print(\"ACC:\", statistics.mean(acc_lr))\n",
        "print(\"AUC:\", statistics.mean(auc_lr))\n",
        "print(\"F1:\", statistics.mean(f1_lr))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}